{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python392jvsc74a57bd0da095f86ab32f3490c8b4dc37c23fc1d5409d02f5085c89ebb1e0696d14ca30b",
   "display_name": "Python 3.9.2 64-bit ('prjenv': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/javascript": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'paths': {'tabulator': 'https://unpkg.com/tabulator-tables@4.9.3/dist/js/tabulator'}});\n      require([], function() {\n      })\n    }\n    if (((window['tabulator'] !== undefined) && (!(window['tabulator'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://unpkg.com/tabulator-tables@4.9.3/dist/js/tabulator.js', 'https://unpkg.com/moment@2.27.0/moment.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) >= 0) { on_load(); continue; }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) >= 0) { on_load(); continue; }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://unpkg.com/tabulator-tables@4.9.3/dist/js/tabulator.js\", \"https://unpkg.com/moment@2.27.0/moment.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.1.min.js\", \"https://unpkg.com/@holoviz/panel@^0.11.2/dist/panel.min.js\"];\n  var js_modules = [];\n  var css_urls = [\"https://unpkg.com/tabulator-tables@4.9.3/dist/css/tabulator_simple.min.css\", \"https://unpkg.com/@holoviz/panel@0.11.2/dist/css/alerts.css\", \"https://unpkg.com/@holoviz/panel@0.11.2/dist/css/card.css\", \"https://unpkg.com/@holoviz/panel@0.11.2/dist/css/dataframe.css\", \"https://unpkg.com/@holoviz/panel@0.11.2/dist/css/json.css\", \"https://unpkg.com/@holoviz/panel@0.11.2/dist/css/loading.css\", \"https://unpkg.com/@holoviz/panel@0.11.2/dist/css/markdown.css\", \"https://unpkg.com/@holoviz/panel@0.11.2/dist/css/widgets.css\"];\n  var inline_js = [\n    function(Bokeh) {\n      inject_raw_css(\"\\n    .bk.pn-loading.arcs:before {\\n      background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiBzdHlsZT0ibWFyZ2luOiBhdXRvOyBiYWNrZ3JvdW5kOiBub25lOyBkaXNwbGF5OiBibG9jazsgc2hhcGUtcmVuZGVyaW5nOiBhdXRvOyIgdmlld0JveD0iMCAwIDEwMCAxMDAiIHByZXNlcnZlQXNwZWN0UmF0aW89InhNaWRZTWlkIj4gIDxjaXJjbGUgY3g9IjUwIiBjeT0iNTAiIHI9IjMyIiBzdHJva2Utd2lkdGg9IjgiIHN0cm9rZT0iI2MzYzNjMyIgc3Ryb2tlLWRhc2hhcnJheT0iNTAuMjY1NDgyNDU3NDM2NjkgNTAuMjY1NDgyNDU3NDM2NjkiIGZpbGw9Im5vbmUiIHN0cm9rZS1saW5lY2FwPSJyb3VuZCI+ICAgIDxhbmltYXRlVHJhbnNmb3JtIGF0dHJpYnV0ZU5hbWU9InRyYW5zZm9ybSIgdHlwZT0icm90YXRlIiByZXBlYXRDb3VudD0iaW5kZWZpbml0ZSIgZHVyPSIxcyIga2V5VGltZXM9IjA7MSIgdmFsdWVzPSIwIDUwIDUwOzM2MCA1MCA1MCI+PC9hbmltYXRlVHJhbnNmb3JtPiAgPC9jaXJjbGU+PC9zdmc+\\\")\\n    }\\n    \");\n    },\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, js_modules, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.holoviews_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'paths': {'tabulator': 'https://unpkg.com/tabulator-tables@4.9.3/dist/js/tabulator'}});\n      require([], function() {\n      })\n    }\n    if (((window['tabulator'] !== undefined) && (!(window['tabulator'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://unpkg.com/tabulator-tables@4.9.3/dist/js/tabulator.js', 'https://unpkg.com/moment@2.27.0/moment.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) >= 0) { on_load(); continue; }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) >= 0) { on_load(); continue; }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://unpkg.com/tabulator-tables@4.9.3/dist/js/tabulator.js\", \"https://unpkg.com/moment@2.27.0/moment.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.1.min.js\", \"https://unpkg.com/@holoviz/panel@^0.11.2/dist/panel.min.js\"];\n  var js_modules = [];\n  var css_urls = [\"https://unpkg.com/tabulator-tables@4.9.3/dist/css/tabulator_simple.min.css\", \"https://unpkg.com/@holoviz/panel@0.11.2/dist/css/alerts.css\", \"https://unpkg.com/@holoviz/panel@0.11.2/dist/css/card.css\", \"https://unpkg.com/@holoviz/panel@0.11.2/dist/css/dataframe.css\", \"https://unpkg.com/@holoviz/panel@0.11.2/dist/css/json.css\", \"https://unpkg.com/@holoviz/panel@0.11.2/dist/css/loading.css\", \"https://unpkg.com/@holoviz/panel@0.11.2/dist/css/markdown.css\", \"https://unpkg.com/@holoviz/panel@0.11.2/dist/css/widgets.css\"];\n  var inline_js = [\n    function(Bokeh) {\n      inject_raw_css(\"\\n    .bk.pn-loading.arcs:before {\\n      background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiBzdHlsZT0ibWFyZ2luOiBhdXRvOyBiYWNrZ3JvdW5kOiBub25lOyBkaXNwbGF5OiBibG9jazsgc2hhcGUtcmVuZGVyaW5nOiBhdXRvOyIgdmlld0JveD0iMCAwIDEwMCAxMDAiIHByZXNlcnZlQXNwZWN0UmF0aW89InhNaWRZTWlkIj4gIDxjaXJjbGUgY3g9IjUwIiBjeT0iNTAiIHI9IjMyIiBzdHJva2Utd2lkdGg9IjgiIHN0cm9rZT0iI2MzYzNjMyIgc3Ryb2tlLWRhc2hhcnJheT0iNTAuMjY1NDgyNDU3NDM2NjkgNTAuMjY1NDgyNDU3NDM2NjkiIGZpbGw9Im5vbmUiIHN0cm9rZS1saW5lY2FwPSJyb3VuZCI+ICAgIDxhbmltYXRlVHJhbnNmb3JtIGF0dHJpYnV0ZU5hbWU9InRyYW5zZm9ybSIgdHlwZT0icm90YXRlIiByZXBlYXRDb3VudD0iaW5kZWZpbml0ZSIgZHVyPSIxcyIga2V5VGltZXM9IjA7MSIgdmFsdWVzPSIwIDUwIDUwOzM2MCA1MCA1MCI+PC9hbmltYXRlVHJhbnNmb3JtPiAgPC9jaXJjbGU+PC9zdmc+\\\")\\n    }\\n    \");\n    },\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, js_modules, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.holoviews_load.v0+json": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "import panel as pn\n",
    "import pandas as pd\n",
    "import que\n",
    "pn.extension(comms='vscode')\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import yahoo_fin.stock_info as yf\n",
    "import warnings\n",
    "from datetime import date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from finquant.portfolio import build_portfolio\n",
    "from finquant.moving_average import ema\n",
    "from finquant.moving_average import sma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_company_financials(ticker_list):\n",
    "    all_financials = {}\n",
    "    if not ticker_list:\n",
    "         return \"Please provide atleast one ticker\"\n",
    "    else: \n",
    "        # avoid looping through dataframes due to loc index issues\n",
    "        ticker_list = list(ticker_list)\n",
    "        for tick in ticker_list:\n",
    "            ticker_report ={}\n",
    "            dict_financials  = yf.get_financials(tick,yearly =True, quarterly = False)\n",
    "            ticker_report[\"income_statement\"]= dict_financials['yearly_income_statement'].fillna(0)\n",
    "            ticker_report[\"balance_sheet\"] = dict_financials['yearly_balance_sheet'].fillna(0)\n",
    "            ticker_report[\"yearly_cash_flow\"] = dict_financials['yearly_cash_flow'].fillna(0)\n",
    "            all_financials[tick] = ticker_report\n",
    "    return all_financials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_company_performance(ticker_list):\n",
    "\n",
    "    all_performance = {}\n",
    "    if not ticker_list:\n",
    "         return \"Please provide atleast one ticker\"\n",
    "    else: \n",
    "        ticker_list = list(ticker_list)\n",
    "        for tick in ticker_list:\n",
    "            performance = {}\n",
    "\n",
    "            try:\n",
    "                dividend = yf.get_dividends(tick)\n",
    "                performance[\"dividend\"] = dividend\n",
    "                earnings = yf.get_earnings_history(tick)\n",
    "                performance[\"earnings\"] = pd.DataFrame(earnings)\n",
    "                all_performance[tick] = performance\n",
    "                # catch exceptions raised on no data available\n",
    "            except Exception as e : \n",
    "                ticker_list.remove(tick)\n",
    "                #print(f\"No dividend for {tick}\") \n",
    "                \n",
    "    return all_performance  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_financial_stats(ticker_list):\n",
    "    all_fin_stats = {}\n",
    "    if not ticker_list:\n",
    "         return \"Please provide atleast one ticker\"\n",
    "    else:\n",
    "        ticker_list = list(ticker_list) \n",
    "        for tick in ticker_list:\n",
    "            try:\n",
    "                fin_stats = yf.get_stats(tick)\n",
    "                all_fin_stats[tick] = fin_stats\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                #ticker_list.remove(tick)\n",
    "    return all_fin_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def persona_return_risk_portfolio(persona_number,score_sort,df_div_payout_ordered,df_Beta):\n",
    "    # 10 year US give bond = ^TNX\n",
    "    ten_year_bond_symbol = \"^TNX\"\n",
    "    # top 2 crypto \n",
    "    bitcoin = \"BTC-USD\"\n",
    "    etherum = \"ETH-USD\"\n",
    "    p_instruments =[]\n",
    "    weight_instruments ={}\n",
    "    five_stocks =score_sort[0:5] \n",
    "    if persona_number == 1:\n",
    "        \n",
    "        \n",
    "        weight_instruments[ten_year_bond_symbol] = 0.8\n",
    "        for st in five_stocks:\n",
    "            weight= (0.2 /5)\n",
    "            weight_instruments[st[0]] = weight\n",
    "        p_instruments.append(weight_instruments)\n",
    "        return p_instruments\n",
    "    elif persona_number == 2:\n",
    "        \n",
    "        \n",
    "        five_stocks =score_sort[0:5] \n",
    "        weight_instruments[ten_year_bond_symbol] = 0.65\n",
    "        for st in five_stocks:\n",
    "            weight= (0.35 /5)\n",
    "            weight_instruments[st[0]] = weight\n",
    "\n",
    "        p_instruments.append(weight_instruments)\n",
    "        return p_instruments\n",
    "    elif persona_number == 3:\n",
    "        \n",
    "        four_stocks =score_sort[0:4] \n",
    "        weight_instruments[ten_year_bond_symbol] = 0.4\n",
    "        # 1 share at 20% \n",
    "        best_div_payout = df_div_payout_ordered.head(1).loc[0:1,\"Ticker\"].values[0]\n",
    "        weight_instruments[best_div_payout] = 0.2\n",
    "\n",
    "        for st in four_stocks:\n",
    "            weight= (0.4 /5)\n",
    "            weight_instruments[st[0]] = weight\n",
    "\n",
    "        p_instruments.append(weight_instruments)\n",
    "        return p_instruments\n",
    "    elif persona_number == 4:\n",
    "        \n",
    "        one = score_sort[0:1][0][0] \n",
    "        weight_instruments[one] = 0.1 \n",
    "        weight_instruments[ten_year_bond_symbol] = 0.05\n",
    "        # 1 share at 20% \n",
    "        best_div_payout = df_div_payout_ordered.head(1).loc[0:1,\"Ticker\"].values[0]\n",
    "        weight_instruments[best_div_payout] = 0.2\n",
    "        weight_instruments[bitcoin] = 0.2\n",
    "        for st in (df_Beta.sort_values(by=\"BETA\", ascending=False).head(3).index):\n",
    "            weight= (0.65 / 3)\n",
    "            weight_instruments[st] = weight\n",
    "\n",
    "        p_instruments.append(weight_instruments) \n",
    "        return p_instruments\n",
    "    elif persona_number ==5:\n",
    "        \n",
    "        weight_instruments[ten_year_bond_symbol] = 0.05\n",
    "        weight_instruments[bitcoin] = (0.45/2)\n",
    "        weight_instruments[etherum] = (0.45/2)\n",
    "        for st in (df_Beta.sort_values(by=\"BETA\", ascending=False).head(3).index):\n",
    "            weight= (0.5 / 3)\n",
    "            weight_instruments[st] = weight\n",
    "\n",
    "        p_instruments.append(weight_instruments)\n",
    "        return p_instruments\n",
    "    else: \n",
    "        return \"Persona identifier should be between one and five\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothetical = pd.read_csv(\"./data/hypo_performance.csv\",index_col=\"Plan\")\n",
    "parameters=['bold_rows', 'index', 'header']\n",
    "df_pane = pn.widgets.DataFrame(hypothetical,name=\"hypot\")\n",
    "#df_pane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = pn.Column('# Risk Tolerance Questions ',sizing_mode=\"stretch_width\",)\n",
    "i=1\n",
    "dict_answer = dict()\n",
    "ques_rad =[]\n",
    "for q in que.questions:\n",
    "    #print (q['choices'])\n",
    "    qid = \"q\" + str(i)\n",
    "    header = pn.pane.Alert(f\"###{q['question']}\")\n",
    "    column.append(header)\n",
    "    if q == que.q10:\n",
    "        column.append(df_pane)\n",
    "    q_options = []\n",
    "    choices=[]\n",
    "    for opt in q['choices']:\n",
    "        q_options.append(opt[1])\n",
    "        choices.append(opt)         \n",
    "   \n",
    "    radio_group = pn.widgets.RadioButtonGroup( name= qid,\n",
    "        options= q_options,\n",
    "        button_type='default',)\n",
    "    ques_rad.append(radio_group)\n",
    "    column.append(radio_group)\n",
    "    dict_answer[qid] = choices\n",
    "    i+=1\n",
    "    column.append( pn.layout.Divider())    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "BokehModel(combine_events=True, render_bundle={'docs_json': {'6378036e-bfec-4453-9f25-fce5689b743c': {'defs': â€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f928967783ee42da8913b83c529a4269"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": "<div style=\"display: none\"></div>",
      "text/plain": [
       "Column(sizing_mode='stretch_width')\n",
       "    [0] Markdown(str)\n",
       "    [1] Alert(str, css_classes=['alert', 'alert-primary']...], margin=(0, 0, 25, 0), sizing_mode='stretch_width')\n",
       "    [2] RadioButtonGroup(name='q1', options=['More than 60', ...], value='More than 60')\n",
       "    [3] Divider()\n",
       "    [4] Alert(str, css_classes=['alert', 'alert-primary']...], margin=(0, 0, 25, 0), sizing_mode='stretch_width')\n",
       "    [5] RadioButtonGroup(name='q2', options=['Within the next year', ...], value='Within the next year')\n",
       "    [6] Divider()\n",
       "    [7] Alert(str, css_classes=['alert', 'alert-primary']...], margin=(0, 0, 25, 0), sizing_mode='stretch_width')\n",
       "    [8] RadioButtonGroup(name='q3', options=['1 week', '1 month', ...], value='1 week')\n",
       "    [9] Divider()\n",
       "    [10] Alert(str, css_classes=['alert', 'alert-primary']...], margin=(0, 0, 25, 0), sizing_mode='stretch_width')\n",
       "    [11] RadioButtonGroup(name='q4', options=['Less than $50,0...], value='Less than $50,000')\n",
       "    [12] Divider()\n",
       "    [13] Alert(str, css_classes=['alert', 'alert-primary']...], margin=(0, 0, 25, 0), sizing_mode='stretch_width')\n",
       "    [14] RadioButtonGroup(name='q5', options=['Very low', 'Below averag...], value='Very low')\n",
       "    [15] Divider()\n",
       "    [16] Alert(str, css_classes=['alert', 'alert-primary']...], margin=(0, 0, 25, 0), sizing_mode='stretch_width')\n",
       "    [17] RadioButtonGroup(name='q6', options=['Deposit it in bank accou...], value='Deposit it in bank accoun...)\n",
       "    [18] Divider()\n",
       "    [19] Alert(str, css_classes=['alert', 'alert-primary']...], margin=(0, 0, 25, 0), sizing_mode='stretch_width')\n",
       "    [20] RadioButtonGroup(name='q7', options=['Absolute loss', ...], value='Absolute loss')\n",
       "    [21] Divider()\n",
       "    [22] Alert(str, css_classes=['alert', 'alert-primary']...], margin=(0, 0, 25, 0), sizing_mode='stretch_width')\n",
       "    [23] RadioButtonGroup(name='q8', options=['I need to see at least a...], value='I need to see a...)\n",
       "    [24] Divider()\n",
       "    [25] Alert(str, css_classes=['alert', 'alert-primary']...], margin=(0, 0, 25, 0), sizing_mode='stretch_width')\n",
       "    [26] RadioButtonGroup(name='q9', options=['Sell all of your remaini...], value='Sell all of y...)\n",
       "    [27] Divider()\n",
       "    [28] Alert(str, css_classes=['alert', 'alert-primary']...], margin=(0, 0, 25, 0), sizing_mode='stretch_width')\n",
       "    [29] DataFrame(name='hypot', value=     Best Case W...)\n",
       "    [30] RadioButtonGroup(name='q10', options=['Plan A', 'Plan B', ...], value='Plan A')\n",
       "    [31] Divider()"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "q_score =[]\n",
    "for ans in ques_rad:   \n",
    "    for opt in dict_answer[ans.name] :\n",
    "        #print(opt) \n",
    "        if ans.value in opt:\n",
    "            q_score.append(int(opt[0]))   \n",
    "    \n",
    "print (q_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_score = sum(q_score)\n",
    "risk_profile =\"Unknown\"\n",
    "risk_persona= 0\n",
    "if total_score < 20:\n",
    "       risk_profile = \"Preservation\"\n",
    "       risk_persona= 1\n",
    "elif total_score >= 20 and total_score < 40:\n",
    "    risk_profile = \"Conservative\"\n",
    "    risk_persona= 2\n",
    "elif total_score >= 40 and total_score < 60:\n",
    "    risk_profile = \"Balanced\"\n",
    "    risk_persona= 3\n",
    "elif total_score >= 60 and total_score <= 80:\n",
    "    risk_profile = \"Aggressive\"\n",
    "    risk_persona= 4\n",
    "else:\n",
    "    risk_profile = \"All Equity\"\n",
    "    risk_persona= 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Preservation'"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "risk_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "persona_number= risk_persona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasdaq_ticker = pd.read_csv('./data/nasdaq_screener.csv')\n",
    "nasdaq_ticker.sort_values(['Market Cap'],ascending=False)\n",
    "fifty_largest= nasdaq_ticker.nlargest(50,'Market Cap')\n",
    "twenty_largest= nasdaq_ticker.nlargest(20,'Market Cap')\n",
    "ticker_list_twenty = twenty_largest['Symbol'].to_list()\n",
    "ticker_list = tuple(ticker_list_twenty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_financials={}\n",
    "all_performance={}\n",
    "while  not (bool(all_financials)):\n",
    "    all_financials = get_company_financials(ticker_list_twenty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#while not (bool(all_performance)):\n",
    "all_performance = get_company_performance(ticker_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_financial_stats={}\n",
    "while not (bool(all_financial_stats)):\n",
    "    all_financial_stats = get_financial_stats(ticker_list_twenty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Add beta code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_beta = {'BETA': {'AAPL': '1.22',\n",
    "  'MSFT': '0.79',\n",
    "  'AMZN': '1.12',\n",
    "  'GOOG': '1.00',\n",
    "  'GOOGL': '1.00',\n",
    "  'FB': '1.29',\n",
    "  'TSLA': '2.01',\n",
    "  'NVDA': '1.38',\n",
    "  'PYPL': '1.15',\n",
    "  'INTC': '0.66',\n",
    "  'ASML': '0.93',\n",
    "  'CMCSA': 1.05,\n",
    "  'NFLX': 0.79,\n",
    "  'ADBE': 0.95,\n",
    "  'CSCO': 0.93,\n",
    "  'AVGO': 0.99,\n",
    "  'PEP': 0.62,\n",
    "  'TXN': 1.07,\n",
    "  'PDD': 1.5,\n",
    "  'TMUS': 0.57}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Beta = pd.DataFrame.from_dict(dict_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       BETA\n",
       "AAPL   1.22\n",
       "ADBE   0.95\n",
       "AMZN   1.12\n",
       "ASML   0.93\n",
       "AVGO   0.99\n",
       "CMCSA  1.05\n",
       "CSCO   0.93\n",
       "FB     1.29\n",
       "GOOG   1.00\n",
       "GOOGL  1.00\n",
       "INTC   0.66\n",
       "MSFT   0.79\n",
       "NFLX   0.79\n",
       "NVDA   1.38\n",
       "PDD     1.5\n",
       "PEP    0.62\n",
       "PYPL   1.15\n",
       "TMUS   0.57\n",
       "TSLA   2.01\n",
       "TXN    1.07"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>BETA</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>AAPL</th>\n      <td>1.22</td>\n    </tr>\n    <tr>\n      <th>ADBE</th>\n      <td>0.95</td>\n    </tr>\n    <tr>\n      <th>AMZN</th>\n      <td>1.12</td>\n    </tr>\n    <tr>\n      <th>ASML</th>\n      <td>0.93</td>\n    </tr>\n    <tr>\n      <th>AVGO</th>\n      <td>0.99</td>\n    </tr>\n    <tr>\n      <th>CMCSA</th>\n      <td>1.05</td>\n    </tr>\n    <tr>\n      <th>CSCO</th>\n      <td>0.93</td>\n    </tr>\n    <tr>\n      <th>FB</th>\n      <td>1.29</td>\n    </tr>\n    <tr>\n      <th>GOOG</th>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>GOOGL</th>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>INTC</th>\n      <td>0.66</td>\n    </tr>\n    <tr>\n      <th>MSFT</th>\n      <td>0.79</td>\n    </tr>\n    <tr>\n      <th>NFLX</th>\n      <td>0.79</td>\n    </tr>\n    <tr>\n      <th>NVDA</th>\n      <td>1.38</td>\n    </tr>\n    <tr>\n      <th>PDD</th>\n      <td>1.5</td>\n    </tr>\n    <tr>\n      <th>PEP</th>\n      <td>0.62</td>\n    </tr>\n    <tr>\n      <th>PYPL</th>\n      <td>1.15</td>\n    </tr>\n    <tr>\n      <th>TMUS</th>\n      <td>0.57</td>\n    </tr>\n    <tr>\n      <th>TSLA</th>\n      <td>2.01</td>\n    </tr>\n    <tr>\n      <th>TXN</th>\n      <td>1.07</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "source": [
    "df_Beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "Cannot interpret '<attribute 'dtype' of 'numpy.generic' objects>' as a data type",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-3174f5e39764>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mdf_ND2EB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_ND2EB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0mdf_ND2EB\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Ticker'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtick\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf_ND2EB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m     \u001b[0mlist_dfs_ND2EB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_ND2EB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\anaconda\\envs\\prjenv\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    260\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m                 data = sanitize_array(data, index, dtype, copy,\n\u001b[1;32m--> 262\u001b[1;33m                                       raise_cast_failure=True)\n\u001b[0m\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\anaconda\\envs\\prjenv\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[1;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             subarr = construct_1d_arraylike_from_scalar(\n\u001b[1;32m--> 642\u001b[1;33m                 value, len(index), dtype)\n\u001b[0m\u001b[0;32m    643\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\anaconda\\envs\\prjenv\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py\u001b[0m in \u001b[0;36mconstruct_1d_arraylike_from_scalar\u001b[1;34m(value, length, dtype)\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1187\u001b[1;33m         \u001b[0msubarr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1188\u001b[0m         \u001b[0msubarr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot interpret '<attribute 'dtype' of 'numpy.generic' objects>' as a data type"
     ]
    }
   ],
   "source": [
    "list_dfs_FCFE  = []\n",
    "list_dfs_ND2EB = []\n",
    "cf_labels = ['netBorrowings','capitalExpenditures','depreciation']\n",
    "is_labels = [\"netIncome\",'ebit']\n",
    "\n",
    "df_ratios = pd.DataFrame()\n",
    "for tick in all_financials.keys():\n",
    "    stock_ratios ={}\n",
    "    yearly_cash_flow = all_financials[tick][\"yearly_cash_flow\"]\n",
    "    income_stmnt = all_financials[tick][\"income_statement\"]\n",
    "    if (cf_labels[0] in yearly_cash_flow.index) and (cf_labels[1] in yearly_cash_flow.index):\n",
    "         capex = yearly_cash_flow.loc[cf_labels[1]]\n",
    "         net_borrow = yearly_cash_flow.loc[cf_labels[0]]\n",
    "         depreciation = yearly_cash_flow.loc[cf_labels[2]]\n",
    "    else: \n",
    "        #print(tick)\n",
    "        del all_financials[tick]    \n",
    "    if is_labels[0] in income_stmnt.index:\n",
    "        net_income = income_stmnt.loc[\"netIncome\"]\n",
    "        ebit = income_stmnt.loc[\"ebit\"]\n",
    "    else: \n",
    "        #print(tick)\n",
    "        del all_financials[tick]\n",
    "    FCFE = net_income - capex + net_borrow\n",
    "    ND_to_EB = net_borrow / (ebit + depreciation)\n",
    "    #print(f\"Ticker {tick} has FCFE of {FCFE}\")\n",
    "    df_FCFE = pd.DataFrame(FCFE).transpose()\n",
    "    df_ND2EB = pd.DataFrame(ND_to_EB).transpose()\n",
    "    \n",
    "    df_ND2EB.columns = df_ND2EB.columns.year\n",
    "    df_ND2EB['Ticker'] = pd.Series(tick, index=df_ND2EB.index)\n",
    "    list_dfs_ND2EB.append(df_ND2EB)\n",
    "    \n",
    "    df_FCFE.columns = df_FCFE.columns.year\n",
    "    df_FCFE['Ticker'] = pd.Series(tick, index=df_FCFE.index)\n",
    "    list_dfs_FCFE.append(df_FCFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat and clean\n",
    "df_all_ND2EB = pd.concat(list_dfs_ND2EB).set_index(\"Ticker\")\n",
    "df_all_ND2EB = df_all_ND2EB.drop(columns=(min(df_all_ND2EB.columns) + 4),axis=1,errors='ignore')\n",
    "df_all_FCFE = pd.concat(list_dfs_FCFE).set_index(\"Ticker\")\n",
    "df_all_FCFE= df_all_FCFE.drop(columns=(min(df_all_FCFE.columns) + 4),axis=1,errors='ignore')\n",
    "df_all_ND2EB.columns.name= \"year\"\n",
    "df_all_FCFE.columns.name= \"year\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_div_payout= []\n",
    "all_div_coverage=[]\n",
    "\n",
    "for tick in all_performance.keys():\n",
    "    \n",
    "    divi = all_performance[tick]['dividend']\n",
    "    ann_total_divi = divi.groupby(divi.index.year).sum()\n",
    "    ann_total_divi = ann_total_divi.T\n",
    "    ann_total_divi = ann_total_divi[ann_total_divi.columns.intersection(df_all_FCFE.columns)]\n",
    "   \n",
    "    earnings = all_performance[tick]['earnings']\n",
    "    eps = earnings[[\"startdatetime\",\"epsactual\"]]\n",
    "    eps.loc[:, (\"startdatetime\")] = pd.to_datetime(eps.loc[:, (\"startdatetime\")], errors=\"coerce\",format=\"%Y-%m-%d\")\n",
    "    eps_annual = eps.groupby(eps.loc[:, (\"startdatetime\")].dt.year).sum()\n",
    "    eps_annual = eps_annual.T\n",
    "    eps_annual = eps_annual[eps_annual.columns.intersection(df_all_FCFE.columns)]\n",
    "    div_coverage = pd.DataFrame(eps_annual.loc['epsactual'] / ann_total_divi.loc[\"dividend\"]).T\n",
    "    div_coverage[\"Ticker\"] = tick\n",
    "    div_coverage =div_coverage.set_index(\"Ticker\")\n",
    "    all_div_coverage.append(div_coverage.dropna())\n",
    "   \n",
    "    div_payout =  pd.DataFrame(ann_total_divi.loc[\"dividend\"] / eps_annual.loc['epsactual']).T\n",
    "    div_payout[\"Ticker\"] = tick\n",
    "    div_payout =div_payout.set_index(\"Ticker\")\n",
    "    all_div_payout.append(div_payout.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat and clean\n",
    "df_div_payout = pd.concat(all_div_payout)\n",
    "df_div_payout.columns.name= \"year\"\n",
    "df_div_coverage= pd.concat(all_div_coverage)\n",
    "df_div_coverage.columns.name= \"year\"\n",
    "df_div_payout['mean'] = df_div_payout.mean(axis=1)\n",
    "df_div_payout_ordered = df_div_payout.sort_values(by=['mean'], ascending= False)\n",
    "df_div_payout_ordered = df_div_payout_ordered.reset_index()\n",
    "df_div_coverage['mean'] = df_div_coverage.mean(axis=1)\n",
    "df_div_coverage_ordered = df_div_coverage.sort_values(by=['mean'], ascending= False)\n",
    "df_div_coverage_ordered = df_div_coverage_ordered.reset_index()\n",
    "df_all_FCFE['mean'] = df_all_FCFE.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_ND2EB['mean'] = df_all_ND2EB.mean(axis=1)\n",
    "df_with_divi_FCFE = df_all_FCFE[df_all_FCFE.index.isin(df_div_payout.index)].sort_values(by=['mean'], ascending= False)\n",
    "# df_with_divi_FCFE[\"Rank\"]= lambda t: .strftime('%d-%b-%Y'), inplace=True)\n",
    "df_with_divi_FCFE = df_with_divi_FCFE.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_divi_ND2EB = df_all_ND2EB[df_all_ND2EB.index.isin(df_div_payout.index)].sort_values(by=['mean'], ascending= False)\n",
    "df_with_divi_ND2EB = df_with_divi_ND2EB.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_dfs = []\n",
    "df_with_divi_ND2EB.name=\"ND2EB\"\n",
    "df_with_divi_FCFE.name=\"FCFE\"\n",
    "df_div_coverage_ordered.name=\"div_coverage\"\n",
    "df_div_payout_ordered.name=\"div_payout\"\n",
    "ranked_dfs.append(df_with_divi_ND2EB)\n",
    "ranked_dfs.append(df_with_divi_FCFE)\n",
    "ranked_dfs.append(df_div_coverage_ordered)\n",
    "ranked_dfs.append(df_div_payout_ordered)\n",
    "df_Beta = df_Beta.astype('float')\n",
    "df_Beta.sort_values(by=\"BETA\",ascending=False).head(3).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_stocks = df_div_payout.index.values\n",
    "score_each={}\n",
    "score_each_debug={}\n",
    "for df in ranked_dfs:\n",
    "    for tick in available_stocks:\n",
    "       if tick not in score_each:\n",
    "            score_each[tick] = 0             \n",
    "       score_each[tick] = score_each[tick] + df[df[\"Ticker\"] == tick ].index.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_sort = sorted(score_each.items(), key =  lambda kv:(kv[1], kv[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ten_year_bond_symbol = \"^TNX\"\n",
    "# top 2 crypto \n",
    "bitcoin = \"BTC-USD\"\n",
    "etherum = \"ETH-USD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threemonth_bond = \"^IRX\"\n",
    "bond_price= yf.get_quote_data(threemonth_bond)\n",
    "risk_free_rate = bond_price [\"regularMarketPrice\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "port = persona_return_risk_portfolio(persona_number, score_sort,df_div_payout_ordered,df_Beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#format portfolio in manner expected by libary \n",
    "analytics_dict ={ }\n",
    "i = 0\n",
    "for instrument in port:\n",
    "    for inf in instrument:\n",
    "        dict_stock = { }\n",
    "        dict_stock[\"Name\"] = inf\n",
    "        dict_stock[\"Allocation\"] = instrument[inf] * 100\n",
    "        analytics_dict[i] = dict_stock\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_allocation = pd.DataFrame.from_dict(analytics_dict, orient=\"index\")\n",
    "names = pf_allocation[\"Name\"].values.tolist()\n",
    "pf = build_portfolio(\n",
    "    names=names, pf_allocation=pf_allocation, start_date=ten_years_ago, end_date=today,data_api=\"yfinance\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs ={ }\n",
    "# plotting cumulative returns (price_{t} - price_{t=0}) / price_{t=0}\n",
    "plt_cumm_returns, ax = plt.subplots()\n",
    "ax = pf.comp_cumulative_returns().plot(ax=ax).axhline(y=0, color=\"black\", lw=3)\n",
    "graphs[\"Cummulative Returns\"] = plt_cumm_returns\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# plotting daily log returns\n",
    "plt_dlog_returns, ax = plt.subplots()\n",
    "ax= pf.comp_daily_log_returns().plot(ax=ax).axhline(y=0, color=\"black\")\n",
    "plt.show()\n",
    "graphs[\" Daily Log Returns\" ] = plt_dlog_returns\n",
    "\n",
    "# cumulative log returns\n",
    "plt_clog_returns, ax = plt.subplots()\n",
    "ax = pf.comp_daily_log_returns().cumsum().plot(ax=ax).axhline(y=0, color=\"black\")\n",
    "plt.show()\n",
    "graphs[\" Cumulative Log Returns\" ] = plt_clog_returns\n",
    "\n",
    "# exponential moving average\n",
    "plt_ema_returns, ax = plt.subplots()\n",
    "#ax = pf.data.plot( )\n",
    "# computing exponential moving average and plotting it\n",
    "ax= ema(pf.data).plot(ax=ax,grid=True)\n",
    "plt.show()\n",
    "graphs[\" Exponential Moving Average\" ] = plt_ema_returns\n",
    "\n",
    "\n",
    "# simple moving average\n",
    "plt_sma_returns_50, ax = plt.subplots()\n",
    "#ax = pf.data.plot(grid=True)\n",
    "# computing simple moving average over a span of 50 (trading) days\n",
    "# and plotting it\n",
    "ax = sma(pf.data, span=50).plot(ax=ax,grid=True)\n",
    "plt.show()\n",
    "graphs[\" Simple Moving Average 50 Days \" ] = plt_sma_returns_50\n",
    "\n",
    "# simple moving average\n",
    "plt_sma_returns_100, ax = plt.subplots()\n",
    "#ax = pf.data.plot(grid=True)\n",
    "# computing simple moving average over a span of 50 (trading) days\n",
    "# and plotting it\n",
    "ax = sma(pf.data, span=100).plot(ax=ax,grid=True)\n",
    "plt.show()\n",
    "graphs[\" Simple Moving Average 100 Days\" ] = plt_sma_returns_100\n",
    "\n",
    "# simple moving average\n",
    "plt_sma_returns_200, ax = plt.subplots()\n",
    "#ax = pf.data.plot(grid=True)\n",
    "# computing simple moving average over a span of 50 (trading) days\n",
    "# and plotting it\n",
    "ax = sma(pf.data, span=200).plot(ax=ax,grid=True)\n",
    "plt.show()\n",
    "graphs[\" Simple Moving Average 200 Days\" ] = plt_sma_returns_200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_indi_ma = pn.Column()\n",
    "\n",
    "for stock in pf.stocks.keys():\n",
    "     title = \"Moving Averages for \"\n",
    "     st = pf.get_stock(stock).data.copy(deep=True)\n",
    "     spans = [10, 50, 100, 150, 200]\n",
    "     st_ma=  compute_ma(st, ema, spans, plot=False)\n",
    "     plt_st_ma, ax = plt.subplots()\n",
    "     ax = st_ma.plot(grid=True,ax=ax)\n",
    "     title = title + stock\n",
    "     card = pn.Card(plt_st_ma, title=title)\n",
    "     col_indi_ma.append(card)\n",
    "\n",
    "col_indi_ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_free_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current=  252\n",
    "pf.freq = current\n",
    "pf.risk_free_rate = risk_free_rate\n",
    "\n",
    "# 2.a compute and get new values based on new freq/risk_free_rate\n",
    "exret = pf.comp_expected_return(freq=pf.freq)\n",
    "vol = pf.comp_volatility(freq=pf.freq)\n",
    "sharpe = pf.comp_sharpe()\n",
    "print(\n",
    "    \"For {} trading days and a risk free rate of {}:\".format(pf.freq, pf.risk_free_rate)\n",
    ")\n",
    "print(\"Expected return: {:0.3f}\".format(exret))\n",
    "print(\"Volatility: {:0.3f}\".format(vol))\n",
    "print(\"Sharpe Ratio: {:0.3f}\".format(sharpe))\n",
    "#str_exp_ret=  \"Expected return: {:0.3f}\".format(exret)\n",
    "pn_er = pn.indicators.Number(name='Expected return', value=round(exret,2), format='{value}%',\n",
    "colors=[(33, 'green')])\n",
    "pn_vol = pn.indicators.Number(name='Volatility', value=round(vol,2), format='{value}',\n",
    "colors=[(33, 'red')])\n",
    "pn_sha =pn.indicators.Number(name='Sharpe Ratio', value=round(sharpe,2), format='{value}',\n",
    "colors=[(33, 'orange')])\n",
    "row_current = pn.Row(pn_er,pn_vol,pn_sha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_years=  252*3\n",
    "pf.freq = three_years\n",
    "pf.risk_free_rate = risk_free_rate\n",
    "\n",
    "# 2.a compute and get new values based on new freq/risk_free_rate\n",
    "exret = pf.comp_expected_return(freq=pf.freq)\n",
    "vol = pf.comp_volatility(freq=pf.freq)\n",
    "sharpe = pf.comp_sharpe()\n",
    "print(\n",
    "    \"For {} trading days and a risk free rate of {}:\".format(pf.freq, pf.risk_free_rate)\n",
    ")\n",
    "print(\"Expected return: {:0.3f}\".format(exret))\n",
    "print(\"Volatility: {:0.3f}\".format(vol))\n",
    "print(\"Sharpe Ratio: {:0.3f}\".format(sharpe))\n",
    "#str_exp_ret=  \"Expected return: {:0.3f}\".format(exret)\n",
    "pn_er_three = pn.indicators.Number(name='Expected return', value=round(exret,2), format='{value}%',\n",
    "colors=[(33, 'green')])\n",
    "pn_vol_three = pn.indicators.Number(name='Volatility', value=round(vol,2), format='{value}',\n",
    "colors=[(33, 'red')])\n",
    "pn_sha_three =pn.indicators.Number(name='Sharpe Ratio', value=round(sharpe,2), format='{value}',\n",
    "colors=[(33, 'orange')])\n",
    "row_curr= pn.Row(pn_er_three,pn_vol_three,pn_sha_three)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "five_years=  252*5\n",
    "pf.freq = five_years\n",
    "pf.risk_free_rate = risk_free_rate\n",
    "\n",
    "# 2.a compute and get new values based on new freq/risk_free_rate\n",
    "exret = pf.comp_expected_return(freq=pf.freq)\n",
    "vol = pf.comp_volatility(freq=pf.freq)\n",
    "sharpe = pf.comp_sharpe()\n",
    "print(\n",
    "    \"For {} trading days and a risk free rate of {}:\".format(pf.freq, pf.risk_free_rate)\n",
    ")\n",
    "print(\"Expected return: {:0.3f}\".format(exret))\n",
    "print(\"Volatility: {:0.3f}\".format(vol))\n",
    "print(\"Sharpe Ratio: {:0.3f}\".format(sharpe))\n",
    "pn_er_five=pn.indicators.Number(name='Expected return', value=round(exret,2), format='{value}%',\n",
    "colors=[(33, 'green')])\n",
    "pn_vol_five=pn.indicators.Number(name='Volatility', value=round(vol,2), format='{value}',\n",
    "colors=[(33, 'red')])\n",
    "pn_sha_five=pn.indicators.Number(name='Sharpe Ratio', value=round(sharpe,2), format='{value}',\n",
    "colors=[(33, 'orange')])\n",
    "row_five_years= pn.Row(pn_er_five,pn_vol_five,pn_sha_five)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ten_years_days=  252*10\n",
    "pf.freq = ten_years_days\n",
    "pf.risk_free_rate = risk_free_rate\n",
    "\n",
    "# 2.a compute and get new values based on new freq/risk_free_rate\n",
    "exret = pf.comp_expected_return(freq=pf.freq)\n",
    "vol = pf.comp_volatility(freq=pf.freq)\n",
    "sharpe = pf.comp_sharpe()\n",
    "print(\n",
    "    \"For {} trading days and a risk free rate of {}:\".format(pf.freq, pf.risk_free_rate)\n",
    ")\n",
    "print(\"Expected return: {:0.3f}\".format(exret))\n",
    "print(\"Volatility: {:0.3f}\".format(vol))\n",
    "print(\"Sharpe Ratio: {:0.3f}\".format(sharpe))\n",
    "pn_er_ten= pn.indicators.Number(name='Expected return', value=round(exret,2), format='{value}%',\n",
    "colors=[(33, 'green')])\n",
    "pn_vol_ten=pn.indicators.Number(name='Volatility', value=round(vol,2), format='{value}',\n",
    "colors=[(33, 'red')])\n",
    "pn_sha_ten=pn.indicators.Number(name='Sharpe Ratio', value=round(sharpe,2), format='{value}',\n",
    "colors=[(33, 'orange')])\n",
    "row_ten_years= pn.Row(pn_er_ten,pn_vol_ten,pn_sha_ten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row1= pn.Row()\n",
    "row2= pn.Row()\n",
    "column= pn.Column()\n",
    "col = 0\n",
    "for graph in graphs.keys():\n",
    "    #mpl_pane = pn.pane(graphs[graph], dpi=144)\n",
    "    card = pn.Card(graphs[graph], title=graph)\n",
    "    if col < 3:\n",
    "        row1.append(card)\n",
    "        col += 1\n",
    "    else:\n",
    "        row2.append(card)\n",
    "        col += 1\n",
    "\n",
    "column.append(row1)\n",
    "column.append(row2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   row_returns = pn.Column(\n",
    "        pn.Card(row_curr, title=\"Current Year\"),\n",
    "        pn.Card(row_three_years, title=\"Three Years\"),\n",
    "        pn.Card(row_five_years, title=\"Five Years\"),\n",
    "        pn.Card(row_five_years, title=\"Ten Years\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabs = pn.Tabs(\n",
    "('Returns Information', row_returns),    \n",
    "('Portfolio Anlaysis', column),\n",
    "(\"Individual Stock Analysis\",col_indi_ma),\n",
    ")\n",
    "tabs"
   ]
  }
 ]
}